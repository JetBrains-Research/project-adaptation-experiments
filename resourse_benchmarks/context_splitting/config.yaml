model_name: "deepseek-ai/deepseek-coder-1.3b-base"
output_file: "output/results.jsonl"
gen_len: 100
doc_len: 1000 # length of each retrieved document
main_len: 1000 # length of the input file that infers generation
num_files: [2, 4, 8, 16] # Number of files in context including main
batch_sizes: [12,6,3,1] # for RTX4090 (for 16k context memory util was only 70%)
num_batches: 20
basics:
  model_name_or_path: "deepseek-ai/deepseek-coder-1.3b-base"
  language: "python" # "python", "kotlin"
  log_model_inputs: false # Whether to log model inputs. Could result in large output files
output:
  results_folder: "/mnt/data/kolomyttseva/long-contex-eval/output/rag/"
  results_filename: "results_multi.jsonl"
data:
  __composer_name: "multi_score"
  composers_list: ["draco", "chunk_score"]
eval:
  _context_size_list: [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16284] # [64, 128, 256, 512, 1024, 2048, 4096, 8192, 16284]
  _context_scopes: ["medium_context"]
  _completion_categories: ["InProject", "InFile"]
  # Eligible categories: ["InProject", "InFile", "InCommit", "OtherAPI", "NonInformative", "Other", "TODO"]
  # The categories' description can be found at
  # for Python https://huggingface.co/datasets/JetBrains-Research/lca-project-level-code-completion
  # for Kotlin https://huggingface.co/datasets/JetBrains-Research/lca-kotlin-project-level-code-completion
  _filter_extensions: true
  _allowed_extensions: [".md", ".txt", ".rst"]
  __batch_size: 1000
_vllm:
  _vllm_args:
    # max_model_len: 16384
    gpu_memory_utilization: 0.90

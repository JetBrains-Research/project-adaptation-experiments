{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "- For long context > 8000 we want more completion length -- >=128 + chunk size 128 \n",
    "- For small context < 4000 we can use smaller completion length -- 64(32) + chunk size 128\n",
    "- Full_file only good on 16k context; otherwise chunking is better\n",
    "- Fixed_line is slightly better than Langchain Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from ipywidgets import interact, widgets\n",
    "from xlwings.utils import chunk\n",
    "import numpy as np\n",
    "\n",
    "from plotter import read_results_path, get_group_columns_path, filter_target_columns, plot_dropdown, plot_dropdown_with_group_by, make_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfixed_line:\\n    - chunk_completion_file.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = [True, False]\\n        - completion_last_chunk_size = 32\\n    - completion_last_chunk_size.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = True\\n        - completion_last_chunk_size = [8, 16, 32, 64, 128]\\n\\nfull_file:\\n    - bm25_word_splitter.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n    - dense_scorer_word_splitter.jsonl\\n        - scorer: dense\\n        - splitter: word_splitter\\n    - scorers_splitters.jsonl\\n        - scorer: iou/bm25\\n        - splitter: line_splitter/word_splitter/model_tokenizer\\n\\nlangchain:\\n    - langchain.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = True\\n        - completion_last_chunk_size = 32\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag_results/python/chunk_score\")\n",
    "\n",
    "full_file_path = base_path / \"full_file\"\n",
    "fixed_line_path = base_path / \"fixed_line\"\n",
    "langchain_path = base_path / \"langchain\"\n",
    "\n",
    "'''\n",
    "fixed_line:\n",
    "    - chunk_completion_file.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = [True, False]\n",
    "        - completion_last_chunk_size = 32\n",
    "    - completion_last_chunk_size.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = True\n",
    "        - completion_last_chunk_size = [8, 16, 32, 64, 128]\n",
    "\n",
    "full_file:\n",
    "    - bm25_word_splitter.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "    - dense_scorer_word_splitter.jsonl\n",
    "        - scorer: dense\n",
    "        - splitter: word_splitter\n",
    "    - scorers_splitters.jsonl\n",
    "        - scorer: iou/bm25\n",
    "        - splitter: line_splitter/word_splitter/model_tokenizer\n",
    "\n",
    "langchain:\n",
    "    - langchain.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = True\n",
    "        - completion_last_chunk_size = 32\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze scorers and splitters\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file\n",
    "- scorer: iou/bm25/dense\n",
    "- splitter: line_splitter/word_splitter/model_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_scorers_splitters = full_file_path / \"scorers_splitters.jsonl\"\n",
    "full_file_dense_word = full_file_path / \"dense_scorer_word_splitter.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns_path(full_file_scorers_splitters)\n",
    "\n",
    "df_full_file_scorers_splitters = read_results_path(full_file_scorers_splitters, group_columns)\n",
    "# Drop all rows where n_grams_max > 1\n",
    "df_full_file_scorers_splitters = df_full_file_scorers_splitters[df_full_file_scorers_splitters['n_grams_max'] == 1]\n",
    "\n",
    "df_full_file_dense_word = read_results_path(full_file_dense_word, group_columns)\n",
    "\n",
    "results_splitters_scorers = pd.concat([df_full_file_scorers_splitters, df_full_file_dense_word], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse scorers for each splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840acfa91aa5466ca4d1682da2349c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), Dropdown(description='metric', options=('em…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'scorer',\n",
    "}\n",
    "make_interaction(results=results_splitters_scorers, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4d7701ad4e4a18b1d5d54b2f85d2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), Text(value='splitter', description='group_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'scorer',\n",
    "    'group_by': 'splitter'\n",
    "\n",
    "}\n",
    "make_interaction(results=results_splitters_scorers, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown_with_group_by, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse splitters for each scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'splitter',\n",
    "}\n",
    "make_interaction(results=results_splitters_scorers, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'splitter',\n",
    "    'group_by': 'scorer'\n",
    "\n",
    "}\n",
    "make_interaction(results=results_splitters_scorers, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown_with_group_by, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse completion_last_chunk_size\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line_completion_last_chunk_size = fixed_line_path / \"completion_last_chunk_size.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns_path(fixed_line_completion_last_chunk_size)\n",
    "\n",
    "results_completion_last_chunk_size = read_results_path(fixed_line_completion_last_chunk_size, group_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results=results_completion_last_chunk_size, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'completion_last_chunk_size'\n",
    "}\n",
    "make_interaction(results=results_completion_last_chunk_size, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown_with_group_by, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunk_completion_file\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = [True, False]\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line_chunk_completion_file = fixed_line_path / \"chunk_completion_file.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns_path(fixed_line_chunk_completion_file)\n",
    "\n",
    "results_chunk_completion_file = read_results_path(fixed_line_chunk_completion_file, group_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results=results_chunk_completion_file, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'chunk_completion_file',\n",
    "\n",
    "}\n",
    "make_interaction(results=results_chunk_completion_file, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown_with_group_by, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunkers\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file/fixed_line/langchain\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "\n",
    "setup only for fixed_line/langchain:\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line = fixed_line_path / \"chunk_completion_file.jsonl\"\n",
    "full_file = full_file_path / \"bm25_word_splitter.jsonl\"\n",
    "langchain = langchain_path / \"langchain.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns_path(full_file)\n",
    "\n",
    "df_fixed_line = read_results_path(fixed_line, group_columns)\n",
    "# Drop all rows where chunk_completion_file is False\n",
    "df_fixed_line = df_fixed_line[df_fixed_line['chunk_completion_file'] == True]\n",
    "df_full_file = read_results_path(full_file, group_columns)\n",
    "df_langchain = read_results_path(langchain, group_columns)\n",
    "\n",
    "results_full_file_fixed_line = pd.concat([df_full_file, df_fixed_line], ignore_index=True)\n",
    "results_full_file_langchain = pd.concat([df_full_file, df_langchain], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Fixed_Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "\n",
    "}\n",
    "make_interaction(results=results_full_file_fixed_line, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 delete_columns=[\"chunk_completion_file\", \"chunker\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "\n",
    "}\n",
    "make_interaction(results=results_full_file_langchain, \n",
    "                 group_columns=group_columns, \n",
    "                 dropdown=plot_dropdown, \n",
    "                 plot_params=plot_params,\n",
    "                 metrics=['em'],\n",
    "                 delete_columns=[\"chunk_completion_file\", \"chunker\"],\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk_exp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

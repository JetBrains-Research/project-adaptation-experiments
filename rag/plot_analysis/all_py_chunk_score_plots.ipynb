{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from ipywidgets import interact, widgets\n",
    "from xlwings.utils import chunk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(file, group_columns):\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            json_data = StringIO(line.strip())\n",
    "            df = pd.read_json(json_data)\n",
    "            df[\"em\"] = df[\"scores\"].apply(lambda x: x[\"exact_match_valid\"][\"mean\"])\n",
    "            grouped = df.groupby(group_columns).agg({\n",
    "                'context_len_config': list,\n",
    "                'em': list,\n",
    "            }).reset_index()\n",
    "            dataframes.append(grouped)\n",
    "    final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_target_columns(results, group_columns, delete_columns=[]):    \n",
    "    target_columns = dict()\n",
    "\n",
    "    for column in group_columns:\n",
    "        column_values = results[column].unique().tolist()\n",
    "        if len(column_values) > 1:\n",
    "            target_columns[column] = sorted(column_values)\n",
    "\n",
    "    # del target_columns[\"stride\"]\n",
    "    for del_col in delete_columns:\n",
    "        del target_columns[del_col]\n",
    "    return target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropdown(plot_by, fontsize=11, **kwargs):\n",
    "    filter_cond = ' & '.join(\n",
    "        [f'{key}==@params[\"{key}\"]' if isinstance(value, (int, float)) \n",
    "         else f'{key}==\"{value}\"' for key, value in kwargs.items()]\n",
    "    )\n",
    "\n",
    "    params = {key: value for key, value in kwargs.items()}\n",
    "    \n",
    "    filtered_df = results.query(filter_cond, local_dict={'params': params})\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        name = f\"{row['chunker']}_{row[plot_by]}\"\n",
    "        ax.plot(row['context_len_config'], row['em'], label=name)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.xlabel('Context length', fontsize=fontsize)\n",
    "    plt.ylabel('EM', fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0.1, 0.63)\n",
    "    \n",
    "    title = ', '.join([f'{key} = {value}' for key, value in kwargs.items()])\n",
    "    plt.title(f\"EM for {title}\", fontsize=fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropdown_with_group_by(plot_by, group_by, fontsize=11, **kwargs):\n",
    "    params = {key: value for key, value in kwargs.items()}\n",
    "    unique_groups = results[group_by].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(unique_groups), figsize=(6 * len(unique_groups), 4))\n",
    "\n",
    "    if len(unique_groups) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, group_value in zip(axes, unique_groups):\n",
    "        params[group_by] = group_value\n",
    "\n",
    "        filter_cond = ' & '.join(\n",
    "            [f'{key}==@params[\"{key}\"]' if isinstance(val, (int, float, np.integer, np.bool_)) \n",
    "             else f'{key}==\"{val}\"' for key, val in params.items()]\n",
    "        )\n",
    "        filtered_df = results.query(filter_cond, local_dict={'params': params})\n",
    "\n",
    "        for idx, row in filtered_df.iterrows():\n",
    "            name = f\"{row['chunker']}_{row[plot_by]}\"\n",
    "            ax.plot(row['context_len_config'], row['em'], label=name)\n",
    "        ax.legend()\n",
    "        \n",
    "        ax.set_xlabel('Context length', fontsize=fontsize)\n",
    "        ax.set_ylabel('EM', fontsize=fontsize)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0.1, 0.63)\n",
    "        ax.set_title(f\"{group_by} = {group_value}\", fontsize=fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze scorers and splitters\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file\n",
    "- scorer: iou/bm25/dense\n",
    "- splitter: line_splitter/word_splitter/model_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/\")\n",
    "# base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag/\")\n",
    "\n",
    "results_full_file_old = base_path / \"results_all_python_chunk_score.jsonl\"\n",
    "results_full_file_new_with_embed = base_path / \"new\" / \"results_embed_full_file_python_chunk_score.jsonl\"\n",
    "\n",
    "df = pd.read_json(results_full_file_old, orient=\"records\", lines=True)\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = df.columns.drop(['context_len_config', 'count', 'context_len_mean', 'time_gen_per_item', 'scores',\n",
    "       'time_data_load_per_item']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse scorers for each splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af1c0fda27947e9af8d1474a5d506ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), IntSlider(value=11, description='fontsize',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_file = read_results(results_full_file_old, group_columns)\n",
    "# Drop all rows where chunk_completion_file is False\n",
    "df_full_file = df_full_file[df_full_file['n_grams_max'] == 1]\n",
    "\n",
    "df_full_file_embed = read_results(results_full_file_new_with_embed, group_columns)\n",
    "\n",
    "results = pd.concat([df_full_file, df_full_file_embed], ignore_index=True)\n",
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"scorer\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'scorer',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20cd633823d4196b31c382982a7eb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), Text(value='splitter', description='group_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown_with_group_by(plot_by, group_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"scorer\", \"splitter\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'scorer',\n",
    "    'group_by': 'splitter'\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "interact(plot_dropdown_with_group_by, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse splitters for each scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973aad48601c4783a141c4118ffb84d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='splitter', description='plot_by'), IntSlider(value=11, description='fontsize…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_file = read_results(results_full_file_old, group_columns)\n",
    "# Drop all rows where chunk_completion_file is False\n",
    "df_full_file = df_full_file[df_full_file['n_grams_max'] == 1]\n",
    "\n",
    "df_full_file_embed = read_results(results_full_file_new_with_embed, group_columns)\n",
    "\n",
    "results = pd.concat([df_full_file, df_full_file_embed], ignore_index=True)\n",
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"splitter\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'splitter',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1c5f0da1064dd5a429f395d67751af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='splitter', description='plot_by'), Text(value='scorer', description='group_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown_with_group_by(plot_by, group_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"scorer\", \"splitter\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'splitter',\n",
    "    'group_by': 'scorer'\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "interact(plot_dropdown_with_group_by, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse completion_last_chunk_size\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/new\")\n",
    "\n",
    "path = base_path / \"results_python_chunk_score.jsonl\"\n",
    "df = pd.read_json(path, orient=\"records\", lines=True)\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = df.columns.drop(['context_len_config', 'count', 'context_len_mean', 'time_gen_per_item', 'scores',\n",
    "       'time_data_load_per_item', 'stride']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1d40d1622b432a906bd9aebf7fd17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = base_path / \"results_python_chunk_score.jsonl\"\n",
    "results = read_results(path, group_columns)\n",
    "\n",
    "target_columns = filter_target_columns(results, [\"chunk_lines_size\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d717b740a1490e9676340078d80146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), Text(value='completion_last_chunk…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown_with_group_by(plot_by, group_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"chunk_lines_size\", \"completion_last_chunk_size\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'completion_last_chunk_size'\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "interact(plot_dropdown_with_group_by, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunk_completion_file\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = [True, False]\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/new\")\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag/\")\n",
    "results_fixed_line = base_path / \"results_fixed_python_chunk_score.jsonl\"\n",
    "\n",
    "df = pd.read_json(results_fixed_line, orient=\"records\", lines=True)\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = df.columns.drop(['context_len_config', 'count', 'context_len_mean', 'time_gen_per_item', 'scores',\n",
    "       'time_data_load_per_item', 'stride']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e90a5108924d2ea590b805524a3ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_fixed_line = base_path / \"results_fixed_python_chunk_score.jsonl\"\n",
    "\n",
    "results = read_results(results_fixed_line, group_columns)\n",
    "\n",
    "target_columns = filter_target_columns(results, [\"chunk_lines_size\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa25d94240c24f32b16d153e1be5dc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), Text(value='chunk_completion_file…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown_with_group_by(plot_by, group_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'chunk_completion_file'\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "interact(plot_dropdown_with_group_by, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunkers\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file/fixed_line/langchain\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "\n",
    "setup only for fixed_line/langchain:\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/new\")\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag/\")\n",
    "results_full_file = base_path / \"results_all_python_chunk_score.jsonl\"\n",
    "\n",
    "df = pd.read_json(results_full_file, orient=\"records\", lines=True)\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = df.columns.drop(['context_len_config', 'count', 'context_len_mean', 'time_gen_per_item', 'scores',\n",
    "       'time_data_load_per_item', 'stride']).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Fixed_Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22663cb161b4041a0f7da7fe7f79eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/new\")\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag/\")\n",
    "\n",
    "results_fixed_line = base_path / \"results_fixed_python_chunk_score.jsonl\"\n",
    "results_full_file = base_path / \"results_all_python_chunk_score.jsonl\"\n",
    "\n",
    "df_fixed_line = read_results(results_fixed_line, group_columns)\n",
    "# Drop all rows where chunk_completion_file is False\n",
    "df_fixed_line = df_fixed_line[df_fixed_line['chunk_completion_file'] == True]\n",
    "\n",
    "df_full_file = read_results(results_full_file, group_columns)\n",
    "\n",
    "results = pd.concat([df_full_file, df_fixed_line], ignore_index=True)\n",
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\", \"chunker\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52db0998db54a71813babf8af153fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_dropdown(plot_by, fontsize=11, **kwargs)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# base_path = Path(\"/mnt/data/galimzyanov/long-context-eval/output/rag/new\")\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag/\")\n",
    "\n",
    "results_full_file = base_path / \"results_all_python_chunk_score.jsonl\"\n",
    "results_langchain = base_path / \"results_langchain_python_chunk_score.jsonl\"\n",
    "\n",
    "df_full_file = read_results(results_full_file, group_columns)\n",
    "df_langchain = read_results(results_langchain, group_columns)\n",
    "\n",
    "results = pd.concat([df_full_file, df_langchain], ignore_index=True)\n",
    "target_columns = filter_target_columns(results, group_columns, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\", \"chunker\"])\n",
    "\n",
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "\n",
    "# Merge additional_params with target_columns\n",
    "all_params = {**target_columns, **additional_params}\n",
    "\n",
    "interact(plot_dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk_exp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

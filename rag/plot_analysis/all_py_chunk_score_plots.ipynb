{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from ipywidgets import interact, widgets\n",
    "from xlwings.utils import chunk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfixed_line:\\n    - chunk_completion_file.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = [True, False]\\n        - completion_last_chunk_size = 32\\n    - completion_last_chunk_size.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = True\\n        - completion_last_chunk_size = [8, 16, 32, 64, 128]\\n\\nfull_file:\\n    - bm25_word_splitter.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n    - dense_scorer_word_splitter.jsonl\\n        - scorer: dense\\n        - splitter: word_splitter\\n    - scorers_splitters.jsonl\\n        - scorer: iou/bm25\\n        - splitter: line_splitter/word_splitter/model_tokenizer\\n\\nlangchain:\\n    - langchain.jsonl\\n        - scorer: bm25\\n        - splitter: word_splitter\\n        - chunk_lines_size = [8, 16, 32, 64, 128]\\n        - chunk_completion_file = True\\n        - completion_last_chunk_size = 32\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path(\"/mnt/data/kolomyttseva/long-contex-eval/output/rag_results/chunk_score\")\n",
    "\n",
    "full_file_path = base_path / \"full_file\"\n",
    "fixed_line_path = base_path / \"fixed_line\"\n",
    "langchain_path = base_path / \"langchain\"\n",
    "\n",
    "'''\n",
    "fixed_line:\n",
    "    - chunk_completion_file.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = [True, False]\n",
    "        - completion_last_chunk_size = 32\n",
    "    - completion_last_chunk_size.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = True\n",
    "        - completion_last_chunk_size = [8, 16, 32, 64, 128]\n",
    "\n",
    "full_file:\n",
    "    - bm25_word_splitter.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "    - dense_scorer_word_splitter.jsonl\n",
    "        - scorer: dense\n",
    "        - splitter: word_splitter\n",
    "    - scorers_splitters.jsonl\n",
    "        - scorer: iou/bm25\n",
    "        - splitter: line_splitter/word_splitter/model_tokenizer\n",
    "\n",
    "langchain:\n",
    "    - langchain.jsonl\n",
    "        - scorer: bm25\n",
    "        - splitter: word_splitter\n",
    "        - chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "        - chunk_completion_file = True\n",
    "        - completion_last_chunk_size = 32\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_results(file, group_columns):\n",
    "\n",
    "    dataframes = []\n",
    "\n",
    "    with open(file, 'r') as file:\n",
    "        for line in file:\n",
    "            json_data = StringIO(line.strip())\n",
    "            df = pd.read_json(json_data)\n",
    "            df[\"em\"] = df[\"scores\"].apply(lambda x: x[\"exact_match_valid\"][\"mean\"])\n",
    "            grouped = df.groupby(group_columns).agg({\n",
    "                'context_len_config': list,\n",
    "                'em': list,\n",
    "            }).reset_index()\n",
    "            dataframes.append(grouped)\n",
    "    final_dataframe = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    return final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_target_columns(results, group_columns, delete_columns=[]):    \n",
    "    target_columns = dict()\n",
    "\n",
    "    for column in group_columns:\n",
    "        column_values = results[column].unique().tolist()\n",
    "        if len(column_values) > 1:\n",
    "            target_columns[column] = sorted(column_values)\n",
    "\n",
    "    # del target_columns[\"stride\"]\n",
    "    for del_col in delete_columns:\n",
    "        del target_columns[del_col]\n",
    "    return target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropdown(results: pd.DataFrame, plot_by, fontsize=11, **kwargs):\n",
    "    filter_cond = ' & '.join(\n",
    "        [f'{key}==@params[\"{key}\"]' if isinstance(value, (int, float)) \n",
    "         else f'{key}==\"{value}\"' for key, value in kwargs.items()]\n",
    "    )\n",
    "\n",
    "    params = {key: value for key, value in kwargs.items()}\n",
    "    \n",
    "    filtered_df = results.query(filter_cond, local_dict={'params': params})\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        name = f\"{row['chunker']}_{row[plot_by]}\"\n",
    "        ax.plot(row['context_len_config'], row['em'], label=name)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.xlabel('Context length', fontsize=fontsize)\n",
    "    plt.ylabel('EM', fontsize=fontsize)\n",
    "    plt.xticks(fontsize=fontsize)\n",
    "    plt.yticks(fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0.1, 0.63)\n",
    "    \n",
    "    title = ', '.join([f'{key} = {value}' for key, value in kwargs.items()])\n",
    "    plt.title(f\"EM for {title}\", fontsize=fontsize)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropdown_with_group_by(results: pd.DataFrame, plot_by, group_by, fontsize=11, **kwargs):\n",
    "    params = {key: value for key, value in kwargs.items()}\n",
    "    unique_groups = results[group_by].unique()\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(unique_groups), figsize=(6 * len(unique_groups), 4))\n",
    "\n",
    "    if len(unique_groups) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, group_value in zip(axes, unique_groups):\n",
    "        params[group_by] = group_value\n",
    "\n",
    "        filter_cond = ' & '.join(\n",
    "            [f'{key}==@params[\"{key}\"]' if isinstance(val, (int, float, np.integer, np.bool_)) \n",
    "             else f'{key}==\"{val}\"' for key, val in params.items()]\n",
    "        )\n",
    "        filtered_df = results.query(filter_cond, local_dict={'params': params})\n",
    "\n",
    "        for idx, row in filtered_df.iterrows():\n",
    "            name = f\"{row['chunker']}_{row[plot_by]}\"\n",
    "            ax.plot(row['context_len_config'], row['em'], label=name)\n",
    "        ax.legend()\n",
    "        \n",
    "        ax.set_xlabel('Context length', fontsize=fontsize)\n",
    "        ax.set_ylabel('EM', fontsize=fontsize)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0.1, 0.63)\n",
    "        ax.set_title(f\"{group_by} = {group_value}\", fontsize=fontsize)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_columns(path):\n",
    "    df = pd.read_json(path, orient=\"records\", lines=True)\n",
    "\n",
    "    drop_columns = ['context_len_config', 'count', 'context_len_mean', 'time_gen_per_item', 'scores', 'time_data_load_per_item']\n",
    "    if 'stride' in df.columns:\n",
    "        drop_columns.append('stride')\n",
    "\n",
    "    # Drop all columns for which we don't want aggregation\n",
    "    group_columns = df.columns.drop(drop_columns).tolist()\n",
    "    return group_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_interaction(results, group_columns, dropdown, additional_params, delete_columns):\n",
    "    target_columns = filter_target_columns(results, group_columns, delete_columns)\n",
    "\n",
    "    additional_params['results'] = widgets.fixed(results)\n",
    "\n",
    "    # Merge additional_params with target_columns\n",
    "    all_params = {**target_columns, **additional_params}\n",
    "\n",
    "    interact(dropdown, **all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze scorers and splitters\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file\n",
    "- scorer: iou/bm25/dense\n",
    "- splitter: line_splitter/word_splitter/model_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_scorers_splitters = full_file_path / \"scorers_splitters.jsonl\"\n",
    "full_file_dense_word = full_file_path / \"dense_scorer_word_splitter.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns(full_file_scorers_splitters)\n",
    "\n",
    "df_full_file_scorers_splitters = read_results(full_file_scorers_splitters, group_columns)\n",
    "# Drop all rows where n_grams_max > 1\n",
    "df_full_file_scorers_splitters = df_full_file_scorers_splitters[df_full_file_scorers_splitters['n_grams_max'] == 1]\n",
    "\n",
    "df_full_file_dense_word = read_results(full_file_dense_word, group_columns)\n",
    "\n",
    "results_splitters_scorers = pd.concat([df_full_file_scorers_splitters, df_full_file_dense_word], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse scorers for each splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6b9be926e14a9c9e879d619969ca04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), IntSlider(value=11, description='fontsize',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'scorer',\n",
    "}\n",
    "make_interaction(results_splitters_scorers, group_columns, plot_dropdown, additional_params, delete_columns=[\"scorer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ed6e2ba5142abade004fa0dce6bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='scorer', description='plot_by'), Text(value='splitter', description='group_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'scorer',\n",
    "    'group_by': 'splitter'\n",
    "}\n",
    "make_interaction(results_splitters_scorers, group_columns, plot_dropdown_with_group_by, additional_params, delete_columns=[\"scorer\", \"splitter\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse splitters for each scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1313414d31754734acff70c71505c7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='splitter', description='plot_by'), IntSlider(value=11, description='fontsize…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'splitter',\n",
    "}\n",
    "make_interaction(results_splitters_scorers, group_columns, plot_dropdown, additional_params, delete_columns=[\"splitter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c817b56f62ae49a184eb1300d8a1a8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='splitter', description='plot_by'), Text(value='scorer', description='group_b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'splitter',\n",
    "    'group_by': 'scorer'\n",
    "}\n",
    "make_interaction(results_splitters_scorers, group_columns, plot_dropdown_with_group_by, additional_params, delete_columns=[\"scorer\", \"splitter\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse completion_last_chunk_size\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line_completion_last_chunk_size = fixed_line_path / \"completion_last_chunk_size.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns(fixed_line_completion_last_chunk_size)\n",
    "\n",
    "results_completion_last_chunk_size = read_results(fixed_line_completion_last_chunk_size, group_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9445badc55c74ef3883889411934ca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results_completion_last_chunk_size, group_columns, plot_dropdown, additional_params, delete_columns=[\"chunk_lines_size\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8b74e1d7224cf385986f9cc205d278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), Text(value='completion_last_chunk…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'completion_last_chunk_size'\n",
    "}\n",
    "make_interaction(results_completion_last_chunk_size, group_columns, plot_dropdown_with_group_by, additional_params, delete_columns=[\"chunk_lines_size\", \"completion_last_chunk_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunk_completion_file\n",
    "\n",
    "chunk_score:\n",
    "- chunker: fixed_line\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = [True, False]\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line_chunk_completion_file = fixed_line_path / \"chunk_completion_file.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns(fixed_line_chunk_completion_file)\n",
    "\n",
    "results_chunk_completion_file = read_results(fixed_line_chunk_completion_file, group_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5062bfaf47f84121a7d03a09f8f8dcdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results_chunk_completion_file, group_columns, plot_dropdown, additional_params, delete_columns=[\"chunk_lines_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b5ffe40162475fb69299b12010540e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), Text(value='chunk_completion_file…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "    'group_by': 'chunk_completion_file',\n",
    "}\n",
    "make_interaction(results_chunk_completion_file, group_columns, plot_dropdown_with_group_by, additional_params, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse chunkers\n",
    "\n",
    "chunk_score:\n",
    "- chunker: full_file/fixed_line/langchain\n",
    "- scorer: bm25\n",
    "- splitter: word_splitter\n",
    "\n",
    "setup only for fixed_line/langchain:\n",
    "- chunk_lines_size = [8, 16, 32, 64, 128]\n",
    "- chunk_completion_file = True\n",
    "- completion_last_chunk_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_line = fixed_line_path / \"chunk_completion_file.jsonl\"\n",
    "full_file = full_file_path / \"bm25_word_splitter.jsonl\"\n",
    "langchain = langchain_path / \"langchain.jsonl\"\n",
    "\n",
    "# Drop all columns for which we don't want aggregation\n",
    "group_columns = get_group_columns(full_file)\n",
    "\n",
    "df_fixed_line = read_results(fixed_line, group_columns)\n",
    "# Drop all rows where chunk_completion_file is False\n",
    "df_fixed_line = df_fixed_line[df_fixed_line['chunk_completion_file'] == True]\n",
    "df_full_file = read_results(full_file, group_columns)\n",
    "df_langchain = read_results(langchain, group_columns)\n",
    "\n",
    "results_full_file_fixed_line = pd.concat([df_full_file, df_fixed_line], ignore_index=True)\n",
    "results_full_file_langchain = pd.concat([df_full_file, df_langchain], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Fixed_Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1404dafe736548fba0b5dc1a74f90475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results_full_file_fixed_line, group_columns, plot_dropdown, additional_params, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\", \"chunker\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full_file VS Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6496e315e24623a53ed6b9bb8331b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='chunk_lines_size', description='plot_by'), IntSlider(value=11, description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "additional_params = {\n",
    "    'plot_by': 'chunk_lines_size',\n",
    "}\n",
    "make_interaction(results_full_file_langchain, group_columns, plot_dropdown, additional_params, delete_columns=[\"chunk_lines_size\", \"chunk_completion_file\", \"chunker\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chunk_exp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
